{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression_and_Neural_Network_with_Scikit-Learn_Distribution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KubnO2egumeN",
        "6jCc3nd2uTpB",
        "DOtAaDjbuTpD",
        "KmBMZFuKuTpE",
        "WCiuG6zruTpF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dddonghwa/IAB/blob/main/Logistic_Regression_and_Neural_Network_with_Scikit_Learn_Distribution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnKXszGIuTo7"
      },
      "source": [
        "# IoT·인공지능·빅데이터 개론 및 실습 (2021년도, 2학기, M2177.004900_001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KubnO2egumeN"
      },
      "source": [
        "##9/10 Logistic Regerssion & Neural Network with Scikit-Learn\n",
        "\n",
        "Adapted by Seonwoo Min from the \"An Introduction to Machine Learning with Scikit-learn\" tutorial (http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
        "\n",
        "In this excercise, we will cover:\n",
        "\n",
        "* Loading an example dataset & preprocessing\n",
        "* Logistic regression & neural network models in scikit-learn\n",
        "* Model training & prediction & evaluation\n",
        "* Model save & load\n",
        "* Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jCc3nd2uTpB"
      },
      "source": [
        "## 1. Loading an example dataset & preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXR0qyJ-uTpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce91b63-b3ed-4ee9-dd4f-f866af6ee9dc"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "data = load_digits()\n",
        "print(data.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FfgysTkuTpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0faf96ba-c52c-47dd-8585-b24295a2adf3"
      },
      "source": [
        "# Data shape & statistics\n",
        "print(\"Data: \", data['data'].shape)\n",
        "print(\"Label:\", data['target'].shape)\n",
        "\n",
        "# Print the number of samples for each class\n",
        "import numpy as np\n",
        "#################### To Do #################################\n",
        "\n",
        "############################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  (1797, 64)\n",
            "Label: (1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG1dHr4CuTpC"
      },
      "source": [
        "#############################################################\n",
        "# Data Visaulization\n",
        "#############################################################\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#################### To Do #################################\n",
        "# Hint: plt.imshow(data['data'][i].reshape(8,8), cmap=plt.cm.gray_r)\n",
        "\n",
        "############################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aeX7JqhuTpD"
      },
      "source": [
        "#############################################################\n",
        "# 1st Preprocessing\n",
        "# Use the first 20 samples in each clss as test data\n",
        "# Use the others as training data\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(test_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie567PVduTpD"
      },
      "source": [
        "#############################################################\n",
        "# 2nd Preprocessing\n",
        "# Let's use only 2 and 3 for binary classification\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(test_data23.shape)\n",
        "print(train_data23.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOtAaDjbuTpD"
      },
      "source": [
        "## 2. Logistic regression & neural network models in scikit-learn\n",
        "\n",
        "For full documentations refer to the following links: <br>\n",
        "Logistic Regression: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html <br>\n",
        "Neural network: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ci9vgU5uTpE"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000, solver='sag')\n",
        "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmBMZFuKuTpE"
      },
      "source": [
        "## 3. Model training & prediction & evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etwr4biEuTpE"
      },
      "source": [
        "#############################################################\n",
        "# Logistic regression model\n",
        "#############################################################\n",
        "# Training\n",
        "LR = LogisticRegression(max_iter=1, solver='sag')\n",
        "LR.fit(train_data23, train_target23)\n",
        "\n",
        "# Prediction\n",
        "train_predict23 = LR.predict(train_data23)\n",
        "test_predict23 = LR.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6DMzuxRuTpF"
      },
      "source": [
        "#############################################################\n",
        "# Neural network model\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "############################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCiuG6zruTpF"
      },
      "source": [
        "## 4. Model save & load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGiSsaIKuTpF"
      },
      "source": [
        "# from sklearn.externals import joblib\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "# save\n",
        "joblib.dump(NN, 'models/NN23.joblib') \n",
        "\n",
        "# load\n",
        "NN_load = joblib.load('models/NN23.joblib') \n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "############################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMb5E4hMuTpF"
      },
      "source": [
        "## 5. Homework\n",
        "Now it's your job to experiment with models and achieve higher accuracy on the  **<font color=red>on the entire dataset</font>**. <br>\n",
        "Try different hyperparameter configurations and save the final model as \"final_model.joblib\" <br>\n",
        "Submit the current **notebook file and the saved final model** on ETL.\n",
        "* Maximum 10 points for >= 97% accuracy on the test set\n",
        "* Maximum 8 points for >= 96% accuracy on the test set\n",
        "* Maximum 6 points for >= 95% accuracy on the test set\n",
        "* Maximum 4 points for >= 94% accuracy on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e62A1qKvcZVE"
      },
      "source": [
        "### 1) import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpuG4WfLM4qH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgu9R--Gcdpv"
      },
      "source": [
        "### 2) load data & split train/test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbDqH-vAG0ok",
        "outputId": "0f950ea0-2acd-43d7-85b4-1a337067df9b"
      },
      "source": [
        "digits = load_digits()\n",
        "\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train = X_scaled[100:]\n",
        "X_test = X_scaled[:100]\n",
        "\n",
        "y_train = y[100:]\n",
        "y_test = y[:100]\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1697, 64) (1697,)\n",
            "(100, 64) (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OivXaSiVcjvK"
      },
      "source": [
        "### 3) model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD1-_IsURhdR",
        "outputId": "8994b8d3-6a1e-4557-ee48-fbdf9aa4b5c9"
      },
      "source": [
        "#############################################################\n",
        "# Try different hyperparameters\n",
        "# Final model training\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "NN = MLPClassifier(hidden_layer_sizes=(270,270,270), activation='relu', solver='adam', \n",
        "                   learning_rate_init = 0.01, max_iter=200, verbose = True, \n",
        "                   early_stopping = True)\n",
        "NN.fit(X_train, y_train)\n",
        "\n",
        "y_pred = NN.predict(X_test)\n",
        "print(NN.score(X_train, y_train))\n",
        "print(NN.score(X_test, y_test))\n",
        "\n",
        "score = NN.score(X_test, y_test)\n",
        "############################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.45103419\n",
            "Validation score: 0.858824\n",
            "Iteration 2, loss = 0.28903768\n",
            "Validation score: 0.929412\n",
            "Iteration 3, loss = 0.12702796\n",
            "Validation score: 0.941176\n",
            "Iteration 4, loss = 0.08187809\n",
            "Validation score: 0.958824\n",
            "Iteration 5, loss = 0.02862866\n",
            "Validation score: 0.935294\n",
            "Iteration 6, loss = 0.02221198\n",
            "Validation score: 0.947059\n",
            "Iteration 7, loss = 0.01579334\n",
            "Validation score: 0.941176\n",
            "Iteration 8, loss = 0.04083326\n",
            "Validation score: 0.935294\n",
            "Iteration 9, loss = 0.03830950\n",
            "Validation score: 0.958824\n",
            "Iteration 10, loss = 0.03732336\n",
            "Validation score: 0.929412\n",
            "Iteration 11, loss = 0.03290691\n",
            "Validation score: 0.941176\n",
            "Iteration 12, loss = 0.03039289\n",
            "Validation score: 0.970588\n",
            "Iteration 13, loss = 0.01202175\n",
            "Validation score: 0.947059\n",
            "Iteration 14, loss = 0.00390966\n",
            "Validation score: 0.970588\n",
            "Iteration 15, loss = 0.00454849\n",
            "Validation score: 0.970588\n",
            "Iteration 16, loss = 0.00357030\n",
            "Validation score: 0.964706\n",
            "Iteration 17, loss = 0.00612574\n",
            "Validation score: 0.952941\n",
            "Iteration 18, loss = 0.01530538\n",
            "Validation score: 0.935294\n",
            "Iteration 19, loss = 0.00860848\n",
            "Validation score: 0.964706\n",
            "Iteration 20, loss = 0.00904389\n",
            "Validation score: 0.947059\n",
            "Iteration 21, loss = 0.02600323\n",
            "Validation score: 0.970588\n",
            "Iteration 22, loss = 0.02344120\n",
            "Validation score: 0.952941\n",
            "Iteration 23, loss = 0.01708977\n",
            "Validation score: 0.976471\n",
            "Iteration 24, loss = 0.01791381\n",
            "Validation score: 0.941176\n",
            "Iteration 25, loss = 0.00619067\n",
            "Validation score: 0.952941\n",
            "Iteration 26, loss = 0.02294261\n",
            "Validation score: 0.964706\n",
            "Iteration 27, loss = 0.01564068\n",
            "Validation score: 0.964706\n",
            "Iteration 28, loss = 0.02782002\n",
            "Validation score: 0.929412\n",
            "Iteration 29, loss = 0.05096207\n",
            "Validation score: 0.947059\n",
            "Iteration 30, loss = 0.03239638\n",
            "Validation score: 0.964706\n",
            "Iteration 31, loss = 0.02031216\n",
            "Validation score: 0.941176\n",
            "Iteration 32, loss = 0.01171337\n",
            "Validation score: 0.947059\n",
            "Iteration 33, loss = 0.00782704\n",
            "Validation score: 0.970588\n",
            "Iteration 34, loss = 0.00544059\n",
            "Validation score: 0.964706\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "0.9899823217442546\n",
            "0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm0bQxGobhWL"
      },
      "source": [
        "### 4) save & load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexbqPILToJE",
        "outputId": "1f1a4cc7-6065-45cd-c19a-2a0b8bf72a69"
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "# save\n",
        "joblib.dump(NN, 'models/NN_'+str(int(score*100))+'.joblib') \n",
        "print(os.listdir('models'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NN_94.joblib', 'NN_96.joblib', 'NN_95.joblib', '.ipynb_checkpoints']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQud1OhYuTpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85f678f-aafc-47be-a70a-fc4b6211530b"
      },
      "source": [
        "#############################################################\n",
        "# Final model test\n",
        "# Load the final model and obatin the test accuracy\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "NN_load = joblib.load('models/NN_96.joblib')\n",
        "y_pred = NN_load.predict(X_test) \n",
        "score = accuracy_score(y_test, y_pred)\n",
        "print(score)\n",
        "############################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-8CmzNhuTpG"
      },
      "source": [
        "\n",
        "### Describe what you did here\n",
        "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your model.\n",
        "* Maximum 10 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0NbdXqzx47b"
      },
      "source": [
        "작성자 학번, 성함 (**반드시 작성해주세요**)\n",
        "\n",
        "학번: 2016-18617\n",
        "\n",
        "이름: 김동화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R7BMd5YuTpG"
      },
      "source": [
        "### 1) Scaling \n",
        "\n",
        "sklearn.preprocessing.MinMaxScaler를 이용하여 데이터를 [0,1] 사이의 값으로 스케일링하였습니다. 최솟값은 0, 최댓값은 1입니다.   \n",
        "데이터 값은 달라졌지만, 이미지 상에서는 동일한 숫자를 인식할 수 있을 정도로 큰 변화는 없었습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb4LhGVWTnKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "7ee3e98e-85c9-4579-eee0-418527f7a05a"
      },
      "source": [
        "print(\"Before Scaling :\\n\")\n",
        "print(X[0].reshape(8,8))\n",
        "print()\n",
        "\n",
        "print(\"After Scaling :\\n\")\n",
        "print(np.round(X_scaled[0].reshape(8,8),2))\n",
        "print()\n",
        "\n",
        "plt.figure()\n",
        "plt.subplot(121)\n",
        "plt.imshow(X[0].reshape(8,8), cmap=plt.cm.gray_r)\n",
        "plt.title('Before Scaling')\n",
        "plt.subplot(122)\n",
        "plt.imshow(X_scaled[0].reshape(8,8), cmap=plt.cm.gray_r)\n",
        "plt.title('After Scaling')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Scaling :\n",
            "\n",
            "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
            " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
            " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
            " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
            " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
            " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
            " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
            " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
            "\n",
            "After Scaling :\n",
            "\n",
            "[[0.   0.   0.31 0.81 0.56 0.06 0.   0.  ]\n",
            " [0.   0.   0.81 0.94 0.62 0.94 0.31 0.  ]\n",
            " [0.   0.19 0.94 0.12 0.   0.69 0.5  0.  ]\n",
            " [0.   0.27 0.75 0.   0.   0.5  0.53 0.  ]\n",
            " [0.   0.36 0.5  0.   0.   0.56 0.57 0.  ]\n",
            " [0.   0.25 0.69 0.   0.06 0.75 0.44 0.  ]\n",
            " [0.   0.12 0.88 0.31 0.62 0.75 0.   0.  ]\n",
            " [0.   0.   0.38 0.81 0.62 0.   0.   0.  ]]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z85eaODo63Yx"
      },
      "source": [
        "### 2) Model Training\n",
        "\n",
        "multi-class 분류 문제이기 때문에 NN 모델인 MLPClassifier를 사용하였고, MLPClassifier의 변수 중에 `hidden_layer_sizes, activation, solver, learning_rate_init, early_stopping`을 변형해가며 성능을 평가해보았습니다. 평가 기준은 정답을 몇퍼센트 맞추었는지를 나타내는 정확도(`accuracy_score`)이었습니다.\n",
        "\n",
        "- `hidden_layer_sizes` : 하나의 은닉층만 해보았을 때 270~290개의 뉴런을 사용하는 것이 좋았고, 하나의 은닉층보다는 세 개의 은닉층을 사용하는 것이 더 높은 효율을 보였습니다.\n",
        "- `activation` : 활성화 함수는 {‘identity’, ‘logistic’, ‘tanh’, ‘relu’} 중 'relu'함수가 가장 효율이 좋았습니다.\n",
        "- `solver` : optimizer는 {‘lbfgs’, ‘sgd’, ‘adam’} 중 'adam'이 가장 효율이 좋았습니다.\n",
        "- `learning_rate_init` : 학습률은 {0.0001, 0.001, 0.01, 0.1} 중에 0.01이 가장 효율이 좋았습니다.\n",
        "- `max_iter`과 `early_stopping` : max_iter은 default 값(200)으로 설정하되 과적합을 막기 위해 early_stopping 를 수행하도록 설정하였습니다. \n",
        "\n",
        "#### 최종 하이퍼파라미터\n",
        "```\n",
        "hidden_layer_sizes=(270,270,270), activation='relu', solver='adam', learning_rate_init = 0.01, \n",
        "max_iter=200, verbose = True, early_stopping = True\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKJMa5Nh9snX"
      },
      "source": [
        "### 3) Save & Load Model\n",
        "\n",
        "모델을 *NN_96.joblib* 이름의 파일로 저장하였고, 저장한 모델을 `joblib.load()`을 통해 불러올 수 있었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4u1G9IEBjQi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}